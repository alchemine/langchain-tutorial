{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory: `SystemMessage` + `history` + `HumanMessage` + `agent_scratchpad`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. History\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `ConversationBufferMemory`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- context: `(HummanMessage, AIMessage)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.cache/pypoetry/virtualenvs/langchain-tutorial-9TtSrW0h-py3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: What's the weather?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in your location is 75 degrees Fahrenheit with partly cloudy skies. There is a 20% chance of rain later this evening.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# from langchain_openai import OpenAI\n",
    "from core.llm import CHAT_LLM as llm\n",
    "\n",
    "# llm = OpenAI(temperature=0)\n",
    "\n",
    "# Here it is by default set to \"AI\"\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")\n",
    "conversation.predict(input=\"What's the weather?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- context: `(HummanMessage, AIMessage, FunctionMessage)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are function calling assistant\n",
      "Human: 안녕~\n",
      "AI: {'arguments': '{\"time\": \"morning\", \"location\": \"Tokyo\"}', 'name': 'greeting'}\n",
      "Function: 안녕하세요!\n",
      "Human: 그래~\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, FunctionMessage\n",
    "from langchain_core.agents import AgentActionMessageLog\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "\n",
    "\n",
    "def generate_artificial_tool_response(tool: str, tool_input: dict):\n",
    "    \"\"\"Generate artificial tool response.\n",
    "\n",
    "    Args:\n",
    "        tool (str): The tool.\n",
    "        tool_input (dict): The tool input.\n",
    "\n",
    "    Returns:\n",
    "        dict: The artificial tool response.\n",
    "    \"\"\"\n",
    "    return AgentActionMessageLog(\n",
    "        tool,\n",
    "        tool_input,\n",
    "        log=f\"\\nInvoking: `{tool}` with `{tool_input}`\\n\\n\\n\",\n",
    "        message_log=[\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        \"arguments\": json.dumps(tool_input, ensure_ascii=False),\n",
    "                        \"name\": tool,\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "agent_action = generate_artificial_tool_response(\n",
    "    tool=\"greeting\",\n",
    "    tool_input={\"time\": \"morning\", \"location\": \"Tokyo\"},\n",
    ")\n",
    "observation = \"안녕하세요!\"\n",
    "\n",
    "memory.chat_memory.add_messages(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕~\"),\n",
    "        *format_to_openai_function_messages([(agent_action, observation)]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = RunnablePassthrough.assign(\n",
    "    history=lambda input: memory.load_memory_variables({})[\"history\"]\n",
    ")\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are function calling assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "template_with_preprocess = preprocess | template\n",
    "val = template_with_preprocess.invoke({\"input\": \"그래~\"})\n",
    "print(val.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Agent scratchpad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are function calling assistant\n",
      "Human: 안녕~\n",
      "AI: {'arguments': '{\"time\": \"morning\", \"location\": \"Tokyo\"}', 'name': 'greeting'}\n",
      "Function: 안녕하세요!\n",
      "Human: 안녕~\n",
      "AI: 어.. 또..?\n",
      "Human: 해봐! 빨리!\n",
      "AI: {'arguments': '{\"utterance\": \"지나친 세일은 게임의 가치를 낮출 뿐입니다\"}', 'name': 'request_again'}\n",
      "Function: 75% 세일을 하지 않을 것입니다\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.agents import AgentActionMessageLog\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "\n",
    "\n",
    "def generate_artificial_tool_response(tool: str, tool_input: dict):\n",
    "    \"\"\"Generate artificial tool response.\n",
    "\n",
    "    Args:\n",
    "        tool (str): The tool.\n",
    "        tool_input (dict): The tool input.\n",
    "\n",
    "    Returns:\n",
    "        dict: The artificial tool response.\n",
    "    \"\"\"\n",
    "    return AgentActionMessageLog(\n",
    "        tool,\n",
    "        tool_input,\n",
    "        log=f\"\\nInvoking: `{tool}` with `{tool_input}`\\n\\n\\n\",\n",
    "        message_log=[\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        \"arguments\": json.dumps(tool_input, ensure_ascii=False),\n",
    "                        \"name\": tool,\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "agent_action = generate_artificial_tool_response(\n",
    "    tool=\"greeting\",\n",
    "    tool_input={\"time\": \"morning\", \"location\": \"Tokyo\"},\n",
    ")\n",
    "observation = \"안녕하세요!\"\n",
    "memory.chat_memory.add_messages(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕~\"),\n",
    "        *format_to_openai_function_messages([(agent_action, observation)]),\n",
    "    ]\n",
    ")\n",
    "memory.chat_memory.add_messages(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕~\"),\n",
    "        AIMessage(content=\"어.. 또..?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent_action = generate_artificial_tool_response(\n",
    "    tool=\"request_again\",\n",
    "    tool_input={\"utterance\": \"지나친 세일은 게임의 가치를 낮출 뿐입니다\"},\n",
    ")\n",
    "observation = \"75% 세일을 하지 않을 것입니다\"\n",
    "\n",
    "\n",
    "preprocess = RunnablePassthrough.assign(\n",
    "    history=lambda input: memory.load_memory_variables({})[\"history\"],\n",
    "    agent_scratchpad=lambda input: format_to_openai_function_messages(\n",
    "        input[\"intermediate_steps\"]\n",
    "    ),\n",
    ")\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are function calling assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "template_with_preprocess = preprocess | template\n",
    "val = template_with_preprocess.invoke(\n",
    "    {\"input\": \"해봐! 빨리!\", \"intermediate_steps\": [(agent_action, observation)]}\n",
    ")\n",
    "print(val.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are AI assistant extracting the location and time information from the user input.\n",
      "\n",
      "History:\n",
      "[HumanMessage(content='안녕~'), AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"time\": \"morning\", \"location\": \"위례신도시\"}', 'name': 'greeting'}}), FunctionMessage(content='안녕하세요!', name='greeting')]\n",
      "\n",
      "Conversation:\n",
      "Human: 나 어디 사는지 알아?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '나 어디 사는지 알아?',\n",
       " 'history': [HumanMessage(content='안녕~'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"time\": \"morning\", \"location\": \"위례신도시\"}', 'name': 'greeting'}}),\n",
       "  FunctionMessage(content='안녕하세요!', name='greeting'),\n",
       "  HumanMessage(content='나 어디 사는지 알아?'),\n",
       "  AIMessage(content='네, 어디 사시는지 알려주세요.')],\n",
       " 'response': '네, 어디 사시는지 알려주세요.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.agents import AgentActionMessageLog\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# from langchain_openai import OpenAI\n",
    "from core.llm import CHAT_LLM as llm\n",
    "\n",
    "\n",
    "def generate_artificial_tool_response(tool: str, tool_input: dict):\n",
    "    \"\"\"Generate artificial tool response.\n",
    "\n",
    "    Args:\n",
    "        tool (str): The tool.\n",
    "        tool_input (dict): The tool input.\n",
    "\n",
    "    Returns:\n",
    "        dict: The artificial tool response.\n",
    "    \"\"\"\n",
    "    return AgentActionMessageLog(\n",
    "        tool,\n",
    "        tool_input,\n",
    "        log=f\"\\nInvoking: `{tool}` with `{tool_input}`\\n\\n\\n\",\n",
    "        message_log=[\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        \"arguments\": json.dumps(tool_input, ensure_ascii=False),\n",
    "                        \"name\": tool,\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "agent_action = generate_artificial_tool_response(\n",
    "    tool=\"greeting\",\n",
    "    tool_input={\"time\": \"morning\", \"location\": \"위례신도시\"},\n",
    ")\n",
    "observation = \"안녕하세요!\"\n",
    "memory.chat_memory.add_messages(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕~\"),\n",
    "        *format_to_openai_function_messages([(agent_action, observation)]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "template = \"\"\"You are AI assistant extracting the location and time information from the user input.\n",
    "\n",
    "History:\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "\n",
    "# llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, prompt=prompt, verbose=True, memory=memory)\n",
    "conversation.invoke({\"input\": \"나 어디 사는지 알아?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-py-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
